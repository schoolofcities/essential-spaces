{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6749dc7-f022-403f-877d-3843d7de32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import unary_union"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2616546c-f575-4b70-8569-62b5944607fd",
   "metadata": {},
   "source": [
    "Update the equity index values from 2024 to 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62bf7e71-0815-4c10-b320-94097cf7f291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_equity_2025 = pd.read_excel('../ct-data/equity-census-2025.xlsx')\n",
    "gdf_equity_map_2024 = gpd.read_file('../ct-data/equity-2024-layer.geo.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ff4a9c1-8488-4a2a-b41c-356544ecdda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force both keys to the same string format with 2 decimal places\n",
    "df_equity_2025[\"Census tract\"] = df_equity_2025[\"Census tract\"].astype(float).map(\"{:.2f}\".format)\n",
    "gdf_equity_map_2024[\"ctuid\"] = gdf_equity_map_2024[\"ctuid\"].astype(float).map(\"{:.2f}\".format)\n",
    "\n",
    "# Rename columns for consistency\n",
    "df_equity_2025.rename(columns={\"Census tract\": \"ctuid\"}, inplace=True)\n",
    "gdf_equity_map_2024 = gdf_equity_map_2024.rename(columns={\"Equity Index\": \"Equity Index 2024\"})\n",
    "\n",
    "# Select and rename columns to merge\n",
    "columns_to_merge = {\n",
    "    \"Normalized Equity Score\": \"Equity Index\",\n",
    "    \"Eviction rate\": \"%Evic\",\n",
    "    \"Unemployment rate\": \"%Unemp\",\n",
    "    \"  % No certificate, diploma or degree\": \"%NoEdu\",\n",
    "    \"Gov transfer\": \"%IncomeGT\"\n",
    "}\n",
    "\n",
    "new_census_vars = list(columns_to_merge.keys())[1:]\n",
    "df_equity_2025[new_census_vars] = df_equity_2025[new_census_vars] * 100\n",
    "df_equity_2025[new_census_vars] = df_equity_2025[new_census_vars].round(2)\n",
    "\n",
    "df_to_merge = df_equity_2025[list(columns_to_merge.keys()) + [\"ctuid\"]]\n",
    "df_to_merge = df_to_merge.rename(columns=columns_to_merge)\n",
    "\n",
    "# Merge data frames on ctuid\n",
    "gdf_equity_map_2025 = gdf_equity_map_2024.merge(df_to_merge, on=\"ctuid\", how=\"left\")\n",
    "\n",
    "# Reorder columns so 'Equity Index' comes before 'Equity Index 2024' and 'geometry' is the last column\n",
    "columns_order = [\n",
    "    'ctuid', 'Equity Index', 'Equity Index 2024'\n",
    "] + [col for col in gdf_equity_map_2025.columns if col not in ['ctuid', 'Equity Index', 'Equity Index 2024', 'geometry']] + ['geometry']\n",
    "gdf_equity_map_2025 = gdf_equity_map_2025[columns_order]\n",
    "\n",
    "gdf_equity_map_2025.to_file(\"../ct-data/equity-2025-layer.geo.json\", driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35409a",
   "metadata": {},
   "source": [
    "Identify the breakpoints for quintiles and investigate composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4fb5e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quintile breakpoints: [0.         0.2985527  0.37396513 0.43815575 0.52905651 1.        ]\n"
     ]
    }
   ],
   "source": [
    "gdf_ct = gpd.read_file('../ct-data/equity-2025-layer.geo.json')\n",
    "\n",
    "# Calculate quintile breakpoints\n",
    "quintiles = np.quantile(gdf_ct['Equity Index'].dropna(), [0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "print(\"Quintile breakpoints:\", quintiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7ecb89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson correlation: 0.8035789674161269\n",
      "Spearman correlation: 0.7887300652384908\n"
     ]
    }
   ],
   "source": [
    "gdf_ct = gpd.read_file('../ct-data/equity-2025-layer.geo.json')\n",
    "gdf_ct = gdf_ct[['ctuid', 'Equity Index 2024', 'Equity Index']].dropna()\n",
    "\n",
    "# Compute Pearson and Spearman correlations\n",
    "pearson_corr, _ = pearsonr(gdf_ct['Equity Index 2024'], gdf_ct['Equity Index'])\n",
    "spearman_corr, _ = spearmanr(gdf_ct['Equity Index 2024'], gdf_ct['Equity Index'])\n",
    "\n",
    "print(f\"Pearson correlation: {pearson_corr}\")\n",
    "print(f\"Spearman correlation: {spearman_corr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "new-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Q1_new     Q2_new     Q3_new     Q4_new     Q5_new\n",
      "Q1_old  63.849765  25.352113   9.859155   0.938967   0.000000\n",
      "Q2_old  25.471698  35.377358  25.000000  13.679245   0.471698\n",
      "Q3_old   8.333333  22.222222  34.259259  30.092593   5.092593\n",
      "Q4_old   1.923077  12.500000  21.153846  37.500000  26.923077\n",
      "Q5_old   0.471698   4.245283   9.433962  17.924528  67.924528\n"
     ]
    }
   ],
   "source": [
    "# Create quintile transition matrix\n",
    "gdf_ct['Quintile_old'] = pd.qcut(gdf_ct['Equity Index 2024'], q=5, labels=[\"Q1_old\", \"Q2_old\", \"Q3_old\", \"Q4_old\", \"Q5_old\"])\n",
    "gdf_ct['Quintile_new'] = pd.qcut(gdf_ct['Equity Index'], q=5, labels=[\"Q1_new\", \"Q2_new\", \"Q3_new\", \"Q4_new\", \"Q5_new\"])\n",
    "\n",
    "# Initialize transition matrix\n",
    "quintile_labels = [\"Q1_old\", \"Q2_old\", \"Q3_old\", \"Q4_old\", \"Q5_old\"]\n",
    "transition_matrix = pd.DataFrame(0.0, index=quintile_labels, columns=[\"Q1_new\", \"Q2_new\", \"Q3_new\", \"Q4_new\", \"Q5_new\"])\n",
    "\n",
    "# Calculate percentages for transitions\n",
    "for old_quintile in quintile_labels:\n",
    "    subset = gdf_ct[gdf_ct['Quintile_old'] == old_quintile]\n",
    "    total_count = len(subset)\n",
    "    if total_count > 0:\n",
    "        for new_quintile in [\"Q1_new\", \"Q2_new\", \"Q3_new\", \"Q4_new\", \"Q5_new\"]:\n",
    "            count_in_new = (subset['Quintile_new'] == new_quintile).sum()\n",
    "            transition_matrix.at[old_quintile, new_quintile] = (count_in_new / total_count) * 100\n",
    "\n",
    "# Save the transition matrix to a CSV file\n",
    "transition_matrix.to_csv('../ct-data/quintile-composition.csv', index=True)\n",
    "\n",
    "print(transition_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7066c7b",
   "metadata": {},
   "source": [
    "Count the number of locations for each census tract as well as an 800m buffer. Further, tag each census tract by the census division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50c811e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "gdf_locations = gpd.read_file('../joined-data/simplified_matches_4326_full.geo.json')\n",
    "gdf_ct = gpd.read_file('../ct-data/equity-2025-layer.geo.json')\n",
    "gdf_gta = gpd.read_file('../ct-data/GTA_CD.gpkg').to_crs(3857)\n",
    "gdf_gta = gdf_gta[gdf_gta['CDNAME'].isin(['Toronto', 'Peel', 'York'])]\n",
    "\n",
    "# Change CRS to 3857 for accurate distance calculations\n",
    "gdf_locations = gdf_locations.to_crs(epsg=3857)\n",
    "gdf_ct = gdf_ct.to_crs(epsg=3857)\n",
    "gdf_gta = gdf_gta.to_crs(epsg=3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f16250e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region_with_max_overlap(tract, gta):\n",
    "    overlaps = gta[gta.intersects(tract.geometry)]\n",
    "    if not overlaps.empty:\n",
    "        overlaps['overlap_area'] = overlaps.geometry.intersection(tract.geometry).area\n",
    "        return overlaps.loc[overlaps['overlap_area'].idxmax(), 'CDNAME']\n",
    "    return None\n",
    "\n",
    "gdf_ct['region'] = gdf_ct.apply(lambda row: get_region_with_max_overlap(row, gdf_gta), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "updated-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1065/1065 [00:03<00:00, 337.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize new columns\n",
    "for col in ['own_count', 'rent_count', 'unknown_count', 'total_count',\n",
    "            'own_count_800m', 'rent_count_800m', 'unknown_count_800m', 'total_count_800m']:\n",
    "    gdf_ct[col] = 0\n",
    "\n",
    "# Iterate over census tracts\n",
    "for idx, tract in tqdm(gdf_ct.iterrows(), total=len(gdf_ct)):\n",
    "    # Locations within the census tract\n",
    "    locations_in_tract = gdf_locations[gdf_locations.within(tract.geometry)]\n",
    "    \n",
    "    # Count tenure categories\n",
    "    gdf_ct.at[idx, 'own_count'] = (locations_in_tract['Tenure'] == 'Own').sum()\n",
    "    gdf_ct.at[idx, 'rent_count'] = (locations_in_tract['Tenure'] == 'Rent').sum()\n",
    "    gdf_ct.at[idx, 'unknown_count'] = (locations_in_tract['Tenure'] == 'Unknown').sum()\n",
    "    gdf_ct.at[idx, 'total_count'] = len(locations_in_tract)\n",
    "\n",
    "    # Buffer geometry for 800m radius around the entire tract\n",
    "    buffer_800m = tract.geometry.buffer(800)\n",
    "    locations_in_buffer = gdf_locations[gdf_locations.geometry.intersects(buffer_800m)]\n",
    "\n",
    "    # centroid = tract.geometry.centroid\n",
    "    # buffer_800m = centroid.buffer(800)\n",
    "    # locations_in_buffer = gdf_locations[gdf_locations.geometry.intersects(buffer_800m)]\n",
    "    \n",
    "    # Count tenure categories within 800m\n",
    "    gdf_ct.at[idx, 'own_count_800m'] = (locations_in_buffer['Tenure'] == 'Own').sum()\n",
    "    gdf_ct.at[idx, 'rent_count_800m'] = (locations_in_buffer['Tenure'] == 'Rent').sum()\n",
    "    gdf_ct.at[idx, 'unknown_count_800m'] = (locations_in_buffer['Tenure'] == 'Unknown').sum()\n",
    "    gdf_ct.at[idx, 'total_count_800m'] = len(locations_in_buffer)\n",
    "\n",
    "# Drop the original columns\n",
    "gdf_ct = gdf_ct.drop(columns=['Own_count', 'Rent_count', 'Unknown_count', 'Total_count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6032ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revert CRS back to 4326 before saving\n",
    "gdf_ct = gdf_ct.to_crs(epsg=4326)\n",
    "\n",
    "# Save updated GeoDataFrame\n",
    "gdf_ct.to_file('../ct-data/ct-data-all.geo.json', driver='GeoJSON')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
